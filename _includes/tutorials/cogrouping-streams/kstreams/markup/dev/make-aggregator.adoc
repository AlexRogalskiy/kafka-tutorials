////
In this file you describe the Kafka streams topology, and should cover the main points of the tutorial.
The text assumes a method buildTopology exists and constructs the Kafka Streams application.  Feel free to modify the text below to suit your needs.
////

The `Aggregator` you saw in the previous step, constructs a map keeping a count of user logins per user, per application, so a map of maps.  Here you'll see the core logic of the `LoginAggregator`, and the code is straightforward, as you can see below.

Each call to `Aggregator.apply` retrieves the user login map for the given application id (or creating one if it doesn't exist).  From there, the `Aggregator` increments the login count for the given user.

++++
<pre class="snippet">
    <code class="java">
        final String userId = loginEvent.getUserId();
        final Map&lt;String, Map&lt;String, Long&gt;&gt; allLogins = loginRollup.getLoginByAppAndUser();
        final Map&lt;String, Long&gt; userLogins = allLogins.computeIfAbsent(appId, key -&gt; new HashMap&lt;&gt;());
        userLogins.compute(userId, (k, v) -&gt; v == null ? 1L : v + 1L);
    </code>
</pre>
++++

While you could add the `Aggregator` instance as an in-line lambda to the topology, creating a separate class allows you to test the aggregator in isolation.

Next, create the following file at `src/main/java/io/confluent/developer/LoginAggregator.java`.

+++++
<pre class="snippet"><code class="java">{% include_raw tutorials/cogrouping-streams/kstreams/code/src/main/java/io/confluent/developer/LoginAggregator.java %}</code></pre>
+++++
